{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEpjWwwQXqxo"
      },
      "source": [
        "# **YOLO**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIwdWcHwIggg"
      },
      "source": [
        "## **IMPORTS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MaUMV3qxH8R-"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics --quiet\n",
        "from ultralytics import YOLO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQvq0Qb1o2QT"
      },
      "outputs": [],
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"FkIXdywiy0LIlW4hIKko\")\n",
        "project = rf.workspace(\"tfg-s3wgw\").project(\"orange-detector-v2\")\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"yolov11\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzKAu2udI1n9"
      },
      "source": [
        "## **TRAINING**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35uj_-MII470"
      },
      "outputs": [],
      "source": [
        "dataset_path = \"./Orange-Detector-V2-1/\"\n",
        "dataset_name = \"Orange-Detector-V2-1\"\n",
        "\n",
        "!cat {dataset_path}/data.yaml # OPCIONAL: VERIFICAR DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZExdtyxKmOM"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "# 1 DATASET\n",
        "# CREAMOS LAS CARPETAS 'VAL' Y 'TEST' A PARTIR DE 'TRAIN'\n",
        "\n",
        "# Porcentaje de validación y test\n",
        "val_ratio = 0.15\n",
        "test_ratio = 0.15\n",
        "\n",
        "random.seed(33)\n",
        "\n",
        "# Crear carpetas de destino\n",
        "for split in ['valid', 'test']:\n",
        "    for sub in ['images', 'labels']:\n",
        "        os.makedirs(os.path.join(dataset_path, split, sub), exist_ok=True)\n",
        "\n",
        "# Listar imágenes de entrenamiento\n",
        "train_img_dir = os.path.join(dataset_path, \"train\", \"images\")\n",
        "train_lbl_dir = os.path.join(dataset_path, \"train\", \"labels\")\n",
        "images = [f for f in os.listdir(train_img_dir) if f.endswith(\".jpg\")]\n",
        "\n",
        "random.shuffle(images)\n",
        "n = len(images)\n",
        "val_split = int(n * val_ratio)\n",
        "test_split = int(n * test_ratio)\n",
        "\n",
        "val_imgs = images[:val_split]\n",
        "test_imgs = images[val_split:val_split + test_split]\n",
        "\n",
        "# Función para mover imagen y su etiqueta\n",
        "def mover(im_list, destino):\n",
        "    for img_name in im_list:\n",
        "        lbl_name = img_name.replace('.jpg', '.txt')\n",
        "        shutil.move(os.path.join(train_img_dir, img_name),\n",
        "                    os.path.join(dataset_path, destino, \"images\", img_name))\n",
        "        shutil.move(os.path.join(train_lbl_dir, lbl_name),\n",
        "                    os.path.join(dataset_path, destino, \"labels\", lbl_name))\n",
        "\n",
        "# Mover archivos\n",
        "mover(val_imgs, \"valid\")\n",
        "mover(test_imgs, \"test\")\n",
        "\n",
        "print(f\"✅ División realizada: {len(val_imgs)} valid | {len(test_imgs)} test | {n - val_split - test_split} train\")\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZwgj9Fr2Q0n"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "# 2 DATASETS (CITDET)\n",
        "\n",
        "# Porcentaje de validación y test\n",
        "val_ratio = 0.15\n",
        "test_ratio = 0.15\n",
        "\n",
        "random.seed(33)\n",
        "\n",
        "# Crear carpetas de destino (validación y test)\n",
        "for split in ['valid', 'test']:\n",
        "    for sub in ['images', 'labels']:\n",
        "        os.makedirs(os.path.join(dataset_path, split, sub), exist_ok=True)\n",
        "\n",
        "# Listar imágenes de tu dataset (sólo imágenes que comienzan con 'arbol')\n",
        "train_img_dir = os.path.join(dataset_path, \"train\", \"images\")\n",
        "train_lbl_dir = os.path.join(dataset_path, \"train\", \"labels\")\n",
        "images = [f for f in os.listdir(train_img_dir) if f.endswith(\".jpg\") and f.startswith(\"arbol\")]\n",
        "imagesAll = [f for f in os.listdir(train_img_dir) if f.endswith(\".jpg\")]\n",
        "\n",
        "random.shuffle(images)\n",
        "n = len(imagesAll)\n",
        "val_split = int(n * val_ratio)\n",
        "test_split = int(n * test_ratio)\n",
        "\n",
        "# Dividir imágenes en validación y test\n",
        "val_imgs = images[:val_split]\n",
        "test_imgs = images[val_split:val_split + test_split]\n",
        "\n",
        "# Función para mover imagen y su etiqueta\n",
        "def mover(im_list, destino):\n",
        "    for img_name in im_list:\n",
        "        lbl_name = img_name.replace('.jpg', '.txt')  # Asumiendo que las etiquetas son .txt\n",
        "        shutil.move(os.path.join(train_img_dir, img_name),\n",
        "                    os.path.join(dataset_path, destino, \"images\", img_name))\n",
        "        shutil.move(os.path.join(train_lbl_dir, lbl_name),\n",
        "                    os.path.join(dataset_path, destino, \"labels\", lbl_name))\n",
        "\n",
        "# Mover archivos\n",
        "mover(val_imgs, \"valid\")\n",
        "mover(test_imgs, \"test\")\n",
        "\n",
        "print(f\"✅ División realizada: {len(val_imgs)} valid | {len(test_imgs)} test | {n - val_split - test_split} train\")\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5sU5uHgwJMWE",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# ENTRENAR MODELO\n",
        "\n",
        "modelo = \"yolo11l\"\n",
        "\n",
        "model = YOLO(f\"{modelo}.pt\")\n",
        "\n",
        "model.train(\n",
        "    data=f\"/home/quirogaalu/TFG/notebooks/{dataset_name}/data.yaml\",\n",
        "    epochs=500, #300\n",
        "    imgsz=640,\n",
        "    batch=8,\n",
        "    patience=50, #30\n",
        "    device=0,\n",
        "    name=f\"{modelo}_naranjas\",\n",
        "    project='./runs/detect',\n",
        "    exist_ok=True,\n",
        "    save=True,\n",
        "    plots=True,\n",
        "\n",
        "    hsv_h=0.05, # 0.02 a 0.1\n",
        "    hsv_s=0.4, # 0.3 a 0.5\n",
        "    hsv_v=0.4, # 0.3 a 0.5\n",
        "    degrees=0.1,\n",
        "    scale=0.1, # 0.1 a 0.2\n",
        "    shear=2.5,\n",
        "    perspective=0.0001,\n",
        "    fliplr=0.5,\n",
        "\n",
        "    # DESACTIVADOS: quiero que el modelo se fije en el centro\n",
        "    translate=0.0,\n",
        "    mosaic=0.0,\n",
        "    mixup=0.0,\n",
        "    cutmix=0.0\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKHhzrBMXyYZ"
      },
      "source": [
        "## **TEST**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHjsUjBXyC2H"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# METRICAS DE ENTRENAMIENTO\n",
        "\n",
        "df = pd.read_csv(f'./runs/detect/{modelo}_naranjas/results.csv')\n",
        "\n",
        "# Imprimir las columnas disponibles para inspección\n",
        "print(df.columns)\n",
        "\n",
        "# Acceder a las columnas por su nombre real\n",
        "plt.plot(df['epoch'], df['metrics/precision(B)'], label='Precisión de Entrenamiento')\n",
        "plt.plot(df['epoch'], df['metrics/recall(B)'], label='Recall de Entrenamiento')\n",
        "\n",
        "# Graficar la pérdida\n",
        "plt.plot(df['epoch'], df['train/box_loss'], label='Pérdida de Entrenamiento (Box)')\n",
        "plt.plot(df['epoch'], df['val/box_loss'], label='Pérdida de Validación (Box)')\n",
        "\n",
        "# Agregar detalles\n",
        "plt.xlabel(\"Época\")\n",
        "plt.ylabel(\"Valor\")\n",
        "plt.title(\"Evolución del Entrenamiento\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iY16HK_5TCIA"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from ultralytics import RTDETR\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# EVALUAR EL MODELO\n",
        "\n",
        "model = RTDETR(\"/home/quirogaalu/TFG/models/rt-detr-l.pt\")\n",
        "#model = YOLO(\"/home/quirogaalu/TFG/models/yolov11l_citdet.pt\")\n",
        "\n",
        "metrics = model.val(data=f\"/home/quirogaalu/TFG/notebooks/{dataset_name}/data.yaml\", imgsz=1024)\n",
        "#metrics = model.val(data=f\"/home/quirogaalu/TFG/notebooks/{dataset_name}/data.yaml\", conf=0.001, iou=0.5, imgsz=1024)\n",
        "\n",
        "precision = metrics.box.p.mean()\n",
        "recall = metrics.box.r.mean()\n",
        "map50 = metrics.box.map50\n",
        "map5095 = metrics.box.map\n",
        "\n",
        "\n",
        "# Mostrar numéricamente\n",
        "print(f\"\\n📊 MÉTRICAS DE DESEMPEÑO:\")\n",
        "print(f\"Precision:   {precision:.3f}\")\n",
        "print(f\"Recall:      {recall:.3f}\")\n",
        "print(f\"mAP50:       {map50:.3f}\")\n",
        "print(f\"mAP50-95:    {map5095:.3f}\\n\")\n",
        "\n",
        "# Gráfica de barras horizontal\n",
        "labels = ['Precision', 'Recall', 'mAP50', 'mAP50-95']\n",
        "values = [precision, recall, map50, map5095]\n",
        "\n",
        "plt.figure(figsize=(7, 4))\n",
        "plt.barh(labels, values, color=['#4caf50', '#2196f3', '#ff9800', '#9c27b0'])\n",
        "plt.xlim(0, 1)\n",
        "plt.xlabel('Valor')\n",
        "plt.title('Métricas de evaluación')\n",
        "for i, v in enumerate(values):\n",
        "    plt.text(v + 0.02, i, f\"{v:.2f}\", va='center')\n",
        "plt.grid(True, axis='x', linestyle='--', alpha=0.6)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bajax5-FJfp8"
      },
      "outputs": [],
      "source": [
        "# HACER PREDICCIONES SOBRE TEST\n",
        "\n",
        "results = model.predict(source=f\"{dataset_path}/test/images\", save=True, imgsz=1024)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07LKviTmO3RC"
      },
      "outputs": [],
      "source": [
        "!zip -r ./yolo_results.zip ./runs/detect"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTXbm8LT2Q0p"
      },
      "source": [
        "# **RT-DETR**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTvAzSwG2Q0q"
      },
      "source": [
        "## **IMPORTS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CpL7TzfY2Q0q"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics --quiet\n",
        "from ultralytics import YOLO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NwcM7O6Y2Q0q"
      },
      "outputs": [],
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"FkIXdywiy0LIlW4hIKko\")\n",
        "project = rf.workspace(\"tfg-s3wgw\").project(\"orange-detector-v2\")\n",
        "version = project.version(5)\n",
        "dataset = version.download(\"yolov11\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1Cxnbr82Q0q"
      },
      "source": [
        "## **TRAINING**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vv-QiXGv2Q0q"
      },
      "outputs": [],
      "source": [
        "dataset_path = \"./Orange-Detector-V2-5/\"\n",
        "dataset_name = \"Orange-Detector-V2-5\"\n",
        "\n",
        "!cat {dataset_path}/data.yaml # OPCIONAL: VERIFICAR DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-ZReudi2Q0q"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "# 1 DATASET\n",
        "# CREAMOS LAS CARPETAS 'VAL' Y 'TEST' A PARTIR DE 'TRAIN'\n",
        "\n",
        "# Porcentaje de validación y test\n",
        "val_ratio = 0.15\n",
        "test_ratio = 0.15\n",
        "\n",
        "random.seed(33)\n",
        "\n",
        "# Crear carpetas de destino\n",
        "for split in ['valid', 'test']:\n",
        "    for sub in ['images', 'labels']:\n",
        "        os.makedirs(os.path.join(dataset_path, split, sub), exist_ok=True)\n",
        "\n",
        "# Listar imágenes de entrenamiento\n",
        "train_img_dir = os.path.join(dataset_path, \"train\", \"images\")\n",
        "train_lbl_dir = os.path.join(dataset_path, \"train\", \"labels\")\n",
        "images = [f for f in os.listdir(train_img_dir) if f.endswith(\".jpg\")]\n",
        "\n",
        "random.shuffle(images)\n",
        "n = len(images)\n",
        "val_split = int(n * val_ratio)\n",
        "test_split = int(n * test_ratio)\n",
        "\n",
        "val_imgs = images[:val_split]\n",
        "test_imgs = images[val_split:val_split + test_split]\n",
        "\n",
        "# Función para mover imagen y su etiqueta\n",
        "def mover(im_list, destino):\n",
        "    for img_name in im_list:\n",
        "        lbl_name = img_name.replace('.jpg', '.txt')\n",
        "        shutil.move(os.path.join(train_img_dir, img_name),\n",
        "                    os.path.join(dataset_path, destino, \"images\", img_name))\n",
        "        shutil.move(os.path.join(train_lbl_dir, lbl_name),\n",
        "                    os.path.join(dataset_path, destino, \"labels\", lbl_name))\n",
        "\n",
        "# Mover archivos\n",
        "mover(val_imgs, \"valid\")\n",
        "mover(test_imgs, \"test\")\n",
        "\n",
        "print(f\"✅ División realizada: {len(val_imgs)} valid | {len(test_imgs)} test | {n - val_split - test_split} train\")\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "BbFCJ_4o2Q0q"
      },
      "outputs": [],
      "source": [
        "# ENTRENAR MODELO\n",
        "\n",
        "from ultralytics import RTDETR\n",
        "\n",
        "model = RTDETR(\"rtdetr-l.pt\")\n",
        "\n",
        "model.train(\n",
        "    data=f\"/home/quirogaalu/TFG/notebooks/{dataset_name}/data.yaml\",\n",
        "    epochs=500, #300\n",
        "    imgsz=1024,\n",
        "    batch=8,\n",
        "    patience=50, #30\n",
        "    device=0,\n",
        "    name=\"RTDETR_naranjas\",\n",
        "    project='./runs/detect',\n",
        "    exist_ok=True,\n",
        "    save=True,\n",
        "    plots=True,\n",
        "\n",
        "    hsv_h=0.05, # 0.02 a 0.1\n",
        "    hsv_s=0.4, # 0.3 a 0.5v\n",
        "    hsv_v=0.4, # 0.3 a 0.5\n",
        "    degrees=0.1,\n",
        "    scale=0.1, # 0.1 a 0.2\n",
        "    shear=2.5,\n",
        "    perspective=0.0001,\n",
        "    fliplr=0.5,\n",
        "    flipud=0.0,\n",
        "\n",
        "    # DESACTIVADOS: quiero que el modelo se fije en el centro\n",
        "    translate=0.0,\n",
        "    mosaic=0.0,\n",
        "    mixup=0.0,\n",
        "    cutmix=0.0\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYwgz0qU2Q0r"
      },
      "source": [
        "## **TEST**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UwgYRFd42Q0r"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# Cargar CSV con resultados de entrenamiento\n",
        "df = pd.read_csv('./runs/detect/RTDETR_naranjas/results.csv')\n",
        "\n",
        "# Graficar métricas principales\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "plt.plot(df['epoch'], df['metrics/precision(B)'], label='Precisión')\n",
        "plt.plot(df['epoch'], df['metrics/recall(B)'], label='Recall')\n",
        "plt.plot(df['epoch'], df['metrics/mAP50(B)'], label='mAP@0.5')\n",
        "\n",
        "plt.xlabel(\"Época\")\n",
        "plt.ylabel(\"Valor\")\n",
        "plt.title(\"Evolución de Precisión, Recall y mAP durante el Entrenamiento\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Graficar pérdidas\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "plt.plot(df['epoch'], df['train/giou_loss'], label='GIoU Loss (Train)')\n",
        "plt.plot(df['epoch'], df['val/giou_loss'], label='GIoU Loss (Val)')\n",
        "plt.plot(df['epoch'], df['train/cls_loss'], label='Class Loss (Train)')\n",
        "plt.plot(df['epoch'], df['val/cls_loss'], label='Class Loss (Val)')\n",
        "plt.plot(df['epoch'], df['train/l1_loss'], label='L1 Loss (Train)')\n",
        "plt.plot(df['epoch'], df['val/l1_loss'], label='L1 Loss (Val)')\n",
        "\n",
        "plt.xlabel(\"Época\")\n",
        "plt.ylabel(\"Pérdida\")\n",
        "plt.title(\"Evolución de las Pérdidas durante el Entrenamiento\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPra-_2M2Q0r"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# EVALUAR EL MODELO\n",
        "\n",
        "#metrics = model.val(conf=0.4, iou=0.5)\n",
        "metrics = model.val()\n",
        "\n",
        "precision = metrics.box.p.mean()\n",
        "recall = metrics.box.r.mean()\n",
        "map50 = metrics.box.map50\n",
        "map5095 = metrics.box.map\n",
        "\n",
        "\n",
        "# Mostrar numéricamente\n",
        "print(f\"\\n📊 MÉTRICAS DE DESEMPEÑO:\")\n",
        "print(f\"Precision:   {precision:.3f}\")\n",
        "print(f\"Recall:      {recall:.3f}\")\n",
        "print(f\"mAP50:       {map50:.3f}\")\n",
        "print(f\"mAP50-95:    {map5095:.3f}\\n\")\n",
        "\n",
        "# Gráfica de barras horizontal\n",
        "labels = ['Precision', 'Recall', 'mAP50', 'mAP50-95']\n",
        "values = [precision, recall, map50, map5095]\n",
        "\n",
        "plt.figure(figsize=(7, 4))\n",
        "plt.barh(labels, values, color=['#4caf50', '#2196f3', '#ff9800', '#9c27b0'])\n",
        "plt.xlim(0, 1)\n",
        "plt.xlabel('Valor')\n",
        "plt.title('Métricas de evaluación')\n",
        "for i, v in enumerate(values):\n",
        "    plt.text(v + 0.02, i, f\"{v:.2f}\", va='center')\n",
        "plt.grid(True, axis='x', linestyle='--', alpha=0.6)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cRo7jad2Q0r"
      },
      "outputs": [],
      "source": [
        "# HACER PREDICCIONES SOBRE TEST\n",
        "\n",
        "results = model.predict(source=f\"{dataset_path}/test/images\", save=True, imgsz=1024)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2uSm_An2Q0r"
      },
      "outputs": [],
      "source": [
        "!zip -r ./detr_results.zip ./runs/detect"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbfZpuXHX7nx"
      },
      "source": [
        "# **FASTER R-CNN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knTPfLXEX7nx"
      },
      "source": [
        "## **IMPORTS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nAOboqgrstOy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch, detectron2\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.utils.logger import setup_logger\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "\n",
        "setup_logger()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9kAnVHHOX7ny"
      },
      "outputs": [],
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"FkIXdywiy0LIlW4hIKko\")\n",
        "project = rf.workspace(\"tfg-s3wgw\").project(\"orange-detector-v2\")\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"coco\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiis6Q60JSRa"
      },
      "source": [
        "## **PREPROCESADO**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7YAM3A20MaB"
      },
      "outputs": [],
      "source": [
        "#!rm -rf /content/Orange-Detector-5/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCHHdb6N2Q0s"
      },
      "outputs": [],
      "source": [
        "#!mv ./Orange-Detector-5 ../datasets/roboflow/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UAU2iSsTJPVS"
      },
      "outputs": [],
      "source": [
        "from detectron2.data.datasets import register_coco_instances\n",
        "\n",
        "dataset_path = \"./Orange-Detector-V2-1/\"\n",
        "\n",
        "register_coco_instances(\"oranges_train\", {}, f\"{dataset_path}train/_annotations.coco.json\", f\"{dataset_path}train/\")\n",
        "\n",
        "register_coco_instances(\"oranges_val\", {}, f\"{dataset_path}valid/_annotations.coco.json\", f\"{dataset_path}valid/\")\n",
        "\n",
        "register_coco_instances(\"oranges_test\", {}, f\"{dataset_path}test/_annotations.coco.json\", f\"{dataset_path}test/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8r11568r4gD"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import cv2\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "\n",
        "my_dataset_train_metadata = MetadataCatalog.get(\"oranges_train\")\n",
        "dataset_dicts = DatasetCatalog.get(\"oranges_train\")\n",
        "\n",
        "for d in random.sample(dataset_dicts, 3):\n",
        "    img = cv2.imread(d[\"file_name\"])\n",
        "    visualizer = Visualizer(img[:, :, ::-1], metadata=my_dataset_train_metadata, scale=0.5)\n",
        "    vis = visualizer.draw_dataset_dict(d)\n",
        "    plt.imshow(vis.get_image())\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syPiRLerX7ny"
      },
      "source": [
        "## **TRAINING**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYjdFUk6sG-0"
      },
      "outputs": [],
      "source": [
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.evaluation import COCOEvaluator\n",
        "\n",
        "class CocoTrainer(DefaultTrainer):\n",
        "\n",
        "  @classmethod\n",
        "  def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
        "\n",
        "    if output_folder is None:\n",
        "        os.makedirs(\"coco_eval\", exist_ok=True)\n",
        "        output_folder = \"coco_eval\"\n",
        "\n",
        "    return COCOEvaluator(dataset_name, cfg, False, output_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3RnPSzk8X7ny",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import detectron2.data.transforms as T\n",
        "from detectron2.checkpoint import DetectionCheckpointer\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.data import DatasetMapper, MetadataCatalog, build_detection_train_loader\n",
        "from detectron2.engine import DefaultTrainer, default_argument_parser, default_setup, launch\n",
        "\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\"))\n",
        "cfg.DATASETS.TRAIN = (\"oranges_train\",)\n",
        "cfg.DATASETS.TEST = (\"oranges_val\",)\n",
        "cfg.DATALOADER.NUM_WORKERS = 8\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\")\n",
        "cfg.SOLVER.IMS_PER_BATCH = 8 # Batch Size\n",
        "cfg.SOLVER.BASE_LR = 0.01 # Learning Rate\n",
        "cfg.SOLVER.WARMUP_ITERS = 1000\n",
        "cfg.SOLVER.MAX_ITER = 2000  # Epochs\n",
        "cfg.SOLVER.STEPS = (1500, 1750)  # learning rate decay schedule\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 256 # The \"RoIHead batch size\" (512 = default)\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2\n",
        "cfg.TEST.EVAL_PERIOD = 250  # evalúa cada 250 iteraciones\n",
        "\n",
        "dataloader = build_detection_train_loader(cfg,\n",
        "   mapper=DatasetMapper(cfg, is_train=True, augmentations=[\n",
        "      T.RandomApply(T.RandomFlip(horizontal=True, vertical=False), prob=0.5),\n",
        "      T.RandomApply(T.RandomRotation(angle=[-10, 10], expand=False, center=None, sample_style='range', interp=None), prob=0.5),\n",
        "      T.RandomApply(T.RandomContrast(intensity_min=0.9, intensity_max=1.1), prob=0.5),\n",
        "      T.RandomApply(T.RandomSaturation(intensity_min=0.6, intensity_max=1.4), prob=0.5),\n",
        "      T.RandomApply(T.RandomBrightness(intensity_min=0.9, intensity_max=1.1), prob=0.5),\n",
        "      T.RandomApply(T.RandomLighting(scale=0.1), prob=0.5)\n",
        "   ]))\n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "trainer = CocoTrainer(cfg)\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PfU0LxPvLsFT"
      },
      "outputs": [],
      "source": [
        "# Look at training curves in tensorboard:\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXkkR1acX7nz"
      },
      "source": [
        "## **TEST**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "-SSG_k5Q2Q0w"
      },
      "outputs": [],
      "source": [
        "from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.engine import DefaultPredictor\n",
        "\n",
        "# SI SE QUIERE CARGAR DIRECTAMENTE EL MODELO\n",
        "\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(\"/home/quirogaalu/TFG/config_faster_rcnn_citdet.yaml\")\n",
        "\n",
        "#cfg.DATASETS.TRAIN = (\"oranges_train\",)\n",
        "#cfg.DATASETS.TEST = (\"oranges_test\",)\n",
        "\n",
        "cfg.MODEL.WEIGHTS = \"/home/quirogaalu/TFG/models/faster_rcnn_citdet.pth\"\n",
        "\n",
        "#cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.001\n",
        "#cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST = 0.5\n",
        "\n",
        "predictor = DefaultPredictor(cfg)\n",
        "\n",
        "evaluator = COCOEvaluator(\"oranges_test\", cfg, False, output_dir=\"./output/\")\n",
        "val_loader = build_detection_test_loader(cfg, \"oranges_test\")\n",
        "results = inference_on_dataset(predictor.model, val_loader, evaluator)\n",
        "\n",
        "print(\"📊 Resultados de evaluación:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fn3gggGSy96Q",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.engine import DefaultPredictor\n",
        "\n",
        "# SI SE QUIERE CARGAR DIRECTAMENTE EL MODELO\n",
        "#cfg = get_cfg()\n",
        "#cfg.merge_from_file(\"ruta_a_config.yaml\")\n",
        "\n",
        "# After training, load the model weights:\n",
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # Umbral de confianza\n",
        "\n",
        "# Create a COCO evaluator and data loader:\n",
        "predictor = DefaultPredictor(cfg)\n",
        "evaluator = COCOEvaluator(\"oranges_test\", cfg, False, output_dir=\"./output/\")\n",
        "val_loader = build_detection_test_loader(cfg, \"oranges_test\")\n",
        "\n",
        "# Run inference and evaluation:\n",
        "results = inference_on_dataset(trainer.model, val_loader, evaluator)\n",
        "print(\"📊 Resultados de evaluación:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4T_5U1DytYGl"
      },
      "outputs": [],
      "source": [
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg.DATASETS.TEST = (\"oranges_test\", )\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # umbral de confianza para inferencia\n",
        "predictor = DefaultPredictor(cfg)\n",
        "test_metadata = MetadataCatalog.get(\"oranges_test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "epIsO7qj2Q0x"
      },
      "outputs": [],
      "source": [
        "with open(\"./output/config.yaml\", \"w\") as f:\n",
        "    f.write(cfg.dump())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJtaZSZytepk",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "\n",
        "# VER PREDICCIONES SOBRE LAS IMÁGENES\n",
        "output_dir = './output/'  # Define el directorio donde quieres guardar las imágenes\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "for imageName in glob.glob(f'{dataset_path}/test/*jpg'):\n",
        "    im = cv2.imread(imageName)\n",
        "    outputs = predictor(im)\n",
        "    v = Visualizer(im[:, :, ::-1], metadata=test_metadata, scale=0.8)\n",
        "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "\n",
        "    # Guardar la imagen procesada\n",
        "    output_image_path = f\"{output_dir}/{imageName.split('/')[-1]}\"  # Cambia el nombre del archivo si es necesario\n",
        "    cv2.imwrite(output_image_path, out.get_image()[:, :, ::-1])  # Guarda la imagen en BGR (OpenCV usa BGR, no RGB)\n",
        "\n",
        "    # Visualización con matplotlib (opcional)\n",
        "    plt.figure(figsize=(12, 8))  # Tamaño grande en pulgadas (ancho x alto)\n",
        "    plt.imshow(out.get_image())\n",
        "    plt.title(imageName.split(\"/\")[-1])\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_R5GsWad2Q0x"
      },
      "outputs": [],
      "source": [
        "!zip -r ./fasterrcnn_results.zip ./output/"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}